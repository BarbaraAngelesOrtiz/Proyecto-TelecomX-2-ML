# üéØ Modelos de machine learning: predicci√≥n de Abandono de Clientes (Churn Prediction)

Este proyecto utiliza t√©cnicas de machine learning para predecir la probabilidad de que un cliente abandone un servicio. El an√°lisis se basa en un dataset con caracter√≠sticas demogr√°ficas y de comportamiento, aplicando modelos como XGBoost, LightGBM, Random Forest, Logistic Regression y un modelo de ensamble (stacking).

El objetivo es desarrollar modelos capaces de identificar de forma anticipada a los clientes con mayor riesgo de cancelar sus servicios. Esto permitir√° a la empresa implementar acciones preventivas para mejorar la retenci√≥n, apoy√°ndose en un pipeline de modelado s√≥lido desde esta fase inicial. Se estudian patrones en variables contractuales, uso de servicios digitales y m√©todos de pago, integrando an√°lisis exploratorio, matriz de correlaciones y explicaciones mediante SHAP.

> üîÑ **Este repositorio corresponde a la segunda etapa del proyecto**, enfocada en *Machine Learning*.  
> La primera parte, dedicada al **an√°lisis e ingenier√≠a de datos** sobre el mismo dataset, puede consultarse aqu√≠: [Challenge2-Alura-Store](https://github.com/BarbaraAngelesOrtiz/Challenge2-Alura-Store).


---

## ‚úèÔ∏èMetas Principales

- Realizar un tratamiento exhaustivo de los datos, incluyendo limpieza, codificaci√≥n y escalado.  
- Analizar la relaci√≥n entre variables para seleccionar las m√°s relevantes para la predicci√≥n.  
- Entrenar y comparar diferentes modelos de clasificaci√≥n para detectar abandono.  
- Evaluar los modelos con m√©tricas que reflejen su desempe√±o real.  
- Analizar la importancia de las variables y su impacto en la predicci√≥n.  
- Presentar conclusiones con recomendaciones basadas en los factores clave que impulsan la cancelaci√≥n.

---

## üí°Actividades Desarrolladas

- Procesamiento y preparaci√≥n de datos para alimentar los modelos de machine learning.  
- Construcci√≥n, entrenamiento y validaci√≥n de modelos predictivos.  
- Interpretaci√≥n de resultados para extraer insights valiosos.  
- Elaboraci√≥n de comunicaci√≥n t√©cnica orientada a la toma de decisiones estrat√©gicas.

---

## üìÅ Estructura del Proyecto

```bash
‚îú‚îÄ‚îÄ TelecomX_LATAM2_es.ipynb  #C√≥digo en espa√±ol        
‚îú‚îÄ‚îÄ TelecomX_LATAM2_en.ipynb  #C√≥digo en ingl√©s          
‚îú‚îÄ‚îÄ imag                      # Gr√°ficos
‚îú‚îÄ‚îÄ src                       # Dataset
‚îú‚îÄ‚îÄ requirements.txt          # Librer√≠as necesarias para ejecutar el proyecto
```

---

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as Utilizadas

Python 3.x
Google Colab (entorno de desarrollo)
Pandas, NumPy (manipulaci√≥n y an√°lisis de datos)
Matplotlib, Seaborn, Plotly (visualizaci√≥n)
scikit-learn (modelado y evaluaci√≥n)
XGBoost, LightGBM (modelos de boosting)
imbalanced-learn (manejo de datos desbalanceados)
SHAP (interpretabilidad de modelos)
Requests (conexi√≥n con APIs externas)
Jupyter Notebooks

---

## üìöDatos

El dataset contiene variables como:

- Tipo de contrato (mensual, dos a√±os)
- Tipo de conexi√≥n a internet (fibra √≥ptica, DSL, sin internet)
- Uso de servicios digitales (streaming, facturaci√≥n electr√≥nica)
- M√©todos de pago (cheque electr√≥nico, tarjeta, d√©bito autom√°tico)
- Antig√ºedad del cliente (tenure)
- Variables de soporte t√©cnico y seguridad online
- Variable objetivo: churn (abandono)

---

## ‚öñÔ∏è Modelos y Evaluaci√≥n

Se implementan y comparan los siguientes modelos:

- Logistic Regression
- Random Forest
- XGBoost
- LightGBM
- Stacking Ensemble
- K-nearest neighbors 

M√©tricas principales usadas:

- Accuracy
- Precision
- Recall
- F1 Score
- ROC AUC

---

## üîñ Comparativa de Modelos

Seg√∫n m√©tricas:

| Modelo                 | Accuracy | Precision | Recall   | F1 Score | ROC AUC  | Observaciones                                            |
| ---------------------- | -------- | --------- | -------- | -------- | -------- | -------------------------------------------------------- |
| **XGBoost**            | 0.783   | 0.575    | 0.701   | 0.631   | 0.845   | Buen balance general, excelente ROC AUC y recall alto  |
| **LightGBM**           | 0.774   | 0.560    | 0.703   | 0.623   | 0.843   | Muy parecido a XGBoost, buen recall y precisi√≥n        |
| **LogisticRegression** | 0.744  | 0.511   | 0.786   | 0.620   | 0.843   | Mejor recall (sensibilidad), menor precisi√≥n           |
| **RandomForest**       | 0.776   | 0.560    | 0.722   | 0.631   | 0.841   | Recall alto, buen balance general                      |
| **Stacking Ensemble**  | 0.779   | 0.578    | 0.623  | 0.600  | 0.834  | Mejor precisi√≥n, un poco menor recall y F1             |
| **KNN**                | 0.714  | 0.475   | 0.725   | 0.574  | 0.794  | Menor accuracy y precisi√≥n, pero recall aceptable      |

Seg√∫n Matriz de Confusi√≥n:

| Modelo                  | TN  | FP  | FN  | TP  | Observaciones                                                                  |
| ----------------------- | --- | --- | --- | --- | ------------------------------------------------------------------------------ |
| **KNN**                 | 735 | 300 | 103 | 271 |  Buen Recall (TP alto) <br>  Muchos Falsos Positivos (FP altos)            |
| **LightGBM**            | 828 | 207 | 111 | 263 |  Buen equilibrio <br>  Algo m√°s FN que KNN, pero menos FP                   |
| **XGBoost**             | 841 | 194 | 112 | 262 |  Mejor TN (FP bajo) <br>  FN similar a LightGBM                             |
| **RandomForest**        | 823 | 212 | 104 | 270 |  Balanceado <br>  FN ligeramente mejor que XGBoost                          |
| **LogisticRegression**  | 754 | 281 | 80  | 294 |  Mejor FN (menos falsos negativos) <br>  M√°s FP (riesgo de costos mayores)  |
| **Ensamble (Stacking)** | 865 | 170 | 141 | 233 |  Mejor TN (menos FP) <br>  M√°s FN (riesgo de perder clientes que abandonan) |


üéØ Modelo seleccionado: **XGBoost** ya que entrega un modelo robusto, con buen poder predictivo y balanceado, ideal para minimizar tanto la p√©rdida de clientes (por recall alto) como evitar falsos alarmas (por precisi√≥n razonable). Es un modelo que se adapta bien a la mayor√≠a de los casos de negocio donde hay que manejar el trade-off entre capturar abandonos y no sobre-reaccionar.

---

## üìä Ejemplo de Visualizaci√≥n

#### Curvas ROC comparativas de todos los modelos
<img width="691" height="547" alt="Curvas ROC comparativas de todos los modelos" src="https://github.com/user-attachments/assets/f004beb9-8c7d-4e6b-9568-b290baa9097b" />

#### Comparaci√≥n de modelos m√©tricas de clasificaci√≥n
<img width="846" height="548" alt="Comparaci√≥n de modelos m√©tricas de clasificaci√≥n" src="https://github.com/user-attachments/assets/cbaa9079-bac5-47aa-84e3-d16b6441f5fa" />

#### Comparativa de desempe√±o entre modelos
<img width="863" height="690" alt="Comparativa de desempe√±o entre modelos" src="https://github.com/user-attachments/assets/106b72fc-2d66-4d0c-9b9e-41397754ca3c" />

#### Curvas Precision-Recall comparativas de todos los modelos
<img width="691" height="547" alt="Curvas Precision-Recall comparativas de todos los modelos" src="https://github.com/user-attachments/assets/21cb3e6a-b952-439d-b0f0-dfd5592820bb" />

---

## üõ†Ô∏è Instrucciones para Ejecutar el Notebook

1. Clon√° o descarg√° este repositorio:

```bash
git clone https://github.com/usuario/proyecto-churn.git 
```
2. Instal√° las dependencias necesarias (recomendado: usar un entorno virtual):

```bash
pip install pandas matplotlib seaborn numpy plotly math matplotlib requests
```
3. Abr√≠ el notebook en Jupyter, VSCode o Google Colab

4. Ejecut√° las celdas secuencialmente para replicar el an√°lisis completo.

---

## üìÇ Project Access

- [Notebook in Spanish](./TelecomX_LATAM2_es.ipynb)
- [Notebook in English](./TelecomX_LATAM2_en.ipynb)

---

## Author
**B√°rbara √Ångeles Ortiz**

<img src="https://github.com/user-attachments/assets/30ea0d40-a7a9-4b19-a835-c474b5cc50fb" width="115">

[LinkedIn](https://www.linkedin.com/in/barbaraangelesortiz/) | [GitHub](https://github.com/BarbaraAngelesOrtiz)

![Status](https://img.shields.io/badge/status-finished-brightgreen) üìÖ Agosto 2025

![Python](https://img.shields.io/badge/python-3.10-blue)

![NumPy](https://img.shields.io/badge/numpy-1.26.0-blue)

![Pandas](https://img.shields.io/badge/pandas-2.1.0-blue)


## Agradecimientos 

<img width="180" height="180" alt="Screenshot 2025-08-13 034705" src="https://github.com/user-attachments/assets/bdfa03bc-d44a-4848-b622-6bac4e2dbc95" />

<img width="180" height="180" alt="images" src="https://github.com/user-attachments/assets/8ca15294-1738-45a7-af65-7a390e468937" />

<img width="180" height="180" alt="Oracle-Next-Education--e16783040" src="https://github.com/user-attachments/assets/8912c5a0-58d7-45af-ba13-d2a9f42cde5a" />


